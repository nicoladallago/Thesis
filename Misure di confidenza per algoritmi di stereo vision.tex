\documentclass[12pt]{report}
\newcommand{\ThesisTitle}{misure di confidenza per algoritmi di \newline stereo vision}
\newcommand{\ThesisAuthor}{Nicola Dal Lago}
\title{\ThesisTitle}
\author{\ThesisAuthor}
\date{}


%%%%%%%%%%%%%%%%%%%%%%%%%% general %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{a4}
\usepackage{color,colortbl}         
\usepackage[english,italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{indentfirst}          
\usepackage{setspace}
\usepackage{float}
\usepackage{appendix}


%%%%%%%%%%%%%%%%%%%%%% fonts & symbols  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{bm}
\usepackage{amsmath,mathtools}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{fancyvrb}  
\usepackage{xspace}
\usepackage{times}    
\usepackage[overload]{textcase} 

%%%%%%%%%%%%%%%%%%%%%% Floats %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{sidecap}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subfig}
\usepackage{wrapfig}
%\usepackage{subcaption}
\usepackage[algo2e,algochapter,ruled,linesnumbered,vlined]{algorithm2e}

%%%%%%%%%%%%%% MATLAB code %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{listings} % inserisce listati di programmi
\definecolor{commenti}{rgb}{0.13,0.55,0.13}
\definecolor{stringhe}{rgb}{0.63,0.125,0.94}
\lstloadlanguages{Matlab}
\lstset{% general command to set parameter(s)
framexleftmargin=0mm,
frame=single,
keywordstyle = \color{blue},% blue keywords
identifierstyle =, % nothing happens
commentstyle = \color{commenti}, % comments
stringstyle = \ttfamily \color{stringhe}, % typewriter type for strings
showstringspaces = false, % no special string spaces
emph = {for, if, then, else, end},
emphstyle = \color{blue},
firstnumber = 1, % numero della prima linea
numbers =left, %  show number_line
numberstyle = \tiny, % style of number_line
stepnumber = 1, % one number_line after stepnumber
numbersep = 5pt,
language = {Matlab}, % per riconoscere la sintassi matlab
extendedchars = true, % per abilitare caratteri particolari
breaklines = true, % per mandare a capo le righe troppo lunghe
breakautoindent = true, % indenta le righe spezzate
breakindent = 30pt, % indenta le righe di 30pt
}

%%%%%%%%%%%%%% page headers and footers %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand{\chaptermark}[1]{
  \markboth{{\bf \chaptername \ \thechapter.} \ #1}{}}
\fancyhead[LE,RO]{\thepage}       
\fancyhead[RE]{\it \small \ThesisTitle }
\fancyhead[LO]{\small \it \leftmark}
\fancyhead[CE,CO]{}                    
\fancyfoot[CE,CO]{}
\fancyfoot[LE,RO]{}
\fancyfoot[RE,LO]{}                    
\renewcommand{\headrulewidth}{1pt}       
\renewcommand{\headheight}{15pt}        
\renewcommand{\footrulewidth}{0pt}      
\addtolength{\headsep}{5mm}

%%%%%%%%%%%%%%%%%%%%% counters %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}    

%%%%%%%%%%%%%%%% utilities %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\nullpage}{\newpage\null\thispagestyle{empty}}  %pagina bianca
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}    %valore assoluto
\DeclareMathOperator*{\argmin}{arg\,min} %argmin


\usepackage[
 colorlinks=false,
 a4paper=true,
 linktocpage=true,
 pagebackref=true,
 pageanchor=true,
 hyperindex=true,
 bookmarks=true,
 bookmarksopen=true,
 bookmarksnumbered=true,
 pdffitwindow=true,
 citecolor=blue,
 urlcolor=blue
 ]%
 {hyperref}

\begin{document}

%%----------------------------------- COPERTINA ------------------------------------------------%%

	\setcounter{page}{0}                  %inizia numerazione pagine
	\renewcommand{\thepage}{\roman{page}} %numerazione romana
	\begin{titlepage}
		\begin{center}
			\vbox to0pt{\vbox to\textheight{\vfill \includegraphics[width=11.5cm]{./figures/unipd-light} \vfill}\vss}

			\hspace{0.5cm}
			\begin{minipage}{.20\textwidth}
  				\includegraphics[height=2.5cm]{./figures/unipd-bn}
			\end{minipage}\begin{minipage}{.90\textwidth}
  				\begin{table}[H]
  					\begin{tabular}{l}
  						\scshape{\Large{\bfseries{Università degli Studi di Padova}}} \\
  						\hline \\
  						\scshape{\large{Dipartimento di Ingegneria dell'Informazione}} \\
  					\end{tabular}
  				\end{table}
			\end{minipage}

			\vspace{1.5cm}
			\emph{\Large{Corso~di~Laurea~in~Ingegneria~dell'Informazione}} \\
			
			\vspace{1.5cm}
			\scshape{\Large{\bfseries{\ThesisTitle}}} \\
			
		\end{center}

		\vfill
		\begin{normalsize}
			\begin{flushleft}
  				\hspace{83pt} \textit{Laureando} \hspace{142pt} \textit{Relatore}\\
  				\vspace{5pt}
  
  				\hspace{62pt} \large{\textbf{Nicola Dal Lago}} \hspace{71pt} \large{\textbf{Prof. Pietro Zanuttigh}}\\
			\end{flushleft}
		\end{normalsize}
		
		\begin{normalsize}
			\begin{flushleft}
		  				\hspace{276pt} \textit{Correlatore}\\
		  
		  				\vspace{5pt}
		  				\hspace{266pt} \large{\textbf{Giulio Marin}}\\
			\end{flushleft}
		\end{normalsize}
		\vfill
		
		\begin{center}
			\hspace{-0.2cm}
			\line(1, 0){360}

			\textsc{Anno Accademico 2013/2014}
		\end{center}
 	\end{titlepage}


%%------------------------------ ABSTRACT -----------------------------------------%%
	\nullpage                      %pagina bianca

	\chapter*{Abstract}
	\label{sec:Abstract}
	\addcontentsline{toc}{chapter}{Abstract}
	\pagestyle{fancy}
	
	Lo scopo di questa tesi è il confronto di varie tecniche di stima della confidenza a partire dai dati acquisiti da una coppia di videocamere. Vengono quindi utilizzate diverse metriche, valutate sia singolarmente che combinate opportunamente. Si confrontano poi i risultati con le mappe di disparità (\textit{ground truth}) disponibili nei dataset di riferimento. Per il calcolo delle disparità è stato usato l'algoritmo \textit{Semi-global matching (SGM)} opportunamente modificato. 
	

%%------------------------------ INDICE -------------------------------------------%%
	\nullpage						%pagina bianca			
	\tableofcontents				%indice
	\nullpage						%pagina bianca

	\renewcommand{\thepage}{\arabic{page}} %numerazione normale
	\setcounter{page}{1}                   %inizia numerazione pagine


%%----------------------------- INTRODUZIONE ---------------------------------------%%	
	\chapter{Introduzione}
	\label{sec:introduzione}
	\pagestyle{fancy}
	
		La visione stereo è un'area attiva della della ricerca da decenni. Negli ultimi anni, gli algoritmi di stereo vision sono maturati a tal punto da essere applicati in un vasto scenario, dall'automazione industriale, al gaming fino alla guida assistita \cite{mercedes}.
	
		\section{Stereopsi}
		\label{sec:Stereopsi}
			\textit{
			La stereopsi è la capacità percettiva che consente di unire le immagini provenienti dai due occhi, che a causa del loro diverso posizionamento strutturale, presentano uno spostamento laterale. Questa disparità viene sfruttata dal cervello per trarre informazioni sulla profondità e sulla posizione spaziale dell'oggetto mirato. Di conseguenza la stereopsi permette di generare la visione tridimensionale. \footnote{\url{https://it.wikipedia.org/wiki/Stereopsi}} \newline}
			
			Si possono quindi identificare i due problemi principali: calcolo delle corrispondenze e triangolazione \cite{fusiello}.\newline
			Il primo consiste nell'accoppiare punti delle due immagini, detti punti coniugati, che sono proiezione dello stesso punto della scena nelle due viste. Il calcolo delle corrispondenze è un problema ben definito in quanto le due immagini differiscono di poco, un punto della scena deve apparire simile nei punti coniugati delle due immagini. Per semplificare il problema e ridurre il numero di errori le due immagini vengono rettificate prima del calcolo delle corrispondenze, in modo che due punti coniugati si trovino sulla stessa retta (detta retta epipolare). Questo si ottiene ruotando le immagini originali attorno ai loro centri ottici finché i piani 
			focali non diventano co-planari (e quindi anche i piani immagine).\newline
			Per triangolazione si intende il calcolo della distanza tra un punto della scena e il piano formato dalle due fotocamere. Nel caso di due fotocamere parallele ed allineate ci si può facilmente ricondurre alla figura \ref{fig:triangolazione}.\newline
			Fissato come riferimento la fotocamera di sinistra si possono scrivere le equazioni di proiezione prospettica:
			
			\begin{equation}
				\begin{dcases}
					\frac{f}{z}=\frac{-u}{x} \\
					\frac{f}{z}=\frac{-u'}{x-b}
				\end{dcases}
				\label{eq:sistema}
			\end{equation}
			
			\begin{figure}[]
				\centering
				\includegraphics[width=0.6\textwidth]{./figures/Triangolazione_stereoscopica.png}
				\caption{Triangolazione stereoscopica.}
				\label{fig:triangolazione}
			\end{figure}
			
			\noindent e risolvendo si ottiene:

			\begin{equation}
				z=\frac{bf}{u'-u}
				\label{eq:soluzione}
			\end{equation}
			
			\noindent dove $b$ è la distanza tra i due centri ottici (\textit{baseline}), $f$ la focale delle fotocamere e $u'-u$ la disparità.
		
		
		\section{Calcolo delle corrispondenze}
		\label{sec:corrispondenze}
		
			\begin{figure}
				\subfloat[][\emph{Fotocamera di destra.}]{\includegraphics[width=.31\textwidth]{./figures/view1.png}\label{subfig:destra}} \quad
				\subfloat[][\emph{Fotocamera di sinistra.}]{\includegraphics[width=.31\textwidth]{./figures/view5.png}\label{subfig:sinistra}} \quad
				\subfloat[][\emph{Mappa di disparità.}]{\includegraphics[width=.31\textwidth]{./figures/disp1.png}\label{subfig:disparità}} 
				
				\caption{Mappa di disparità con immagine di destra come riferimento, immagine presa da \url{http://vision.middlebury.edu/stereo/data/}.}
				\label{fig:disparità}
			\end{figure}
			
			
			
			Il calcolo delle corrispondenze o della disparità è il problema principale della stereo vision.	La disparità è la differenza tra due punti coniugati (vettore), immaginando di sovrapporre le due immagini. Il calcolo delle corrispondenze non è altro che il calcolo della disparità per ogni pixel delle due immagini \cite{fusiello}. Si ottiene quindi una mappa di disparità del tipo di figura \ref{subfig:disparità}. La mappa di disparità non è altro che una matrice di scalari: in ogni cella viene memorizzato la distanza che separa il corrispondente punto dell'immagine di riferimento dal suo punto coniugato.\newline
			Esistono molti algoritmi diversi per il calcolo delle disparità. I metodi \textit{locali} utilizzano per la ricerca del punto coniugato, un piccolo numero di pixel attorno al pixel considerato, approcci tipici di questo tipo sono \textit{correlazione}, \textit{SSD}, \textit{SAD}, \textit{trasformata census}, eccetera \cite{correlation}. I metodi \textit{globali}, invece, sfruttano vincoli non locali per ridurre la sensibilità a regioni per le quali l'accoppiamento fallisce. Ne risulta un problema di ottimizzazione e richiedono un costo computazionale sicuramente maggiore rispetto ai metodi locali. In questa tesi si utilizzano invece dei metodi detti \textit{semi globali}, che non sono altro che una via di mezzo tra i locali e globali; questi considerano un pixel e i suoi vicini per approssimare la soluzione globale. Vengono utilizzati questi tipi di algoritmi sia per ridurre il costo computazionale rispetto ai globali, sia per avere migliore precisione rispetto ai locali \cite{SGM}. La disparità però non è una funzione esatta, in quanto può essere soggetta da rumore (errata illuminazione, mancanza di trama, occlusioni, eccetera) provocando errori nell'algoritmo. Viene quindi generata una funzione detta ‘‘ funzione costo ’’, la quale ha per ascissa tutti i possibili valori di disparità, e per ordinata il valore di costo, che indica quanto quella disparità sia attendibile.  
			
			

%%--------------------------- MISURE DI CONFIDENZA ------------------------------------%%						
	\nullpage
	
	\chapter{Misure di confidenza}
	\label{sec:confidenza}
	\pagestyle{fancy}
	
		Come accennato nella sezione \ref{sec:corrispondenze}, ad ogni pixel dell'immagine di riferimento (destra o sinistra), viene assegnata una funzione costo, la quale identifica quanto una determinata disparità sia esatta per quel pixel.
			
			
		\begin{figure}[<h>]
			\centering
			\subfloat[][\emph{Funzione costo ideale.}]
			{\includegraphics[width=.48\textwidth]{./figures/good_cost.png}} \quad
			\subfloat[][\emph{Funzione costo ambigua.}]
			{\includegraphics[width=.48\textwidth]{./figures/bad_cost.png}}
			\caption{Due possibili funzioni costo.}
			\label{fig:costi}
		\end{figure}	
		
		\noindent Due possibili funzioni costo sono riportate in figura \ref{fig:costi}. E' chiaro che nel primo caso la disparità  è individuata da quell'unico picco; nel secondo caso invece, la funzione è ambigua, in quanto vi sono diversi picchi, e non è quindi più così immediato trovare l'esatta disparità. Si rende quindi necessario lo studio di varie tecniche per misurare la confidenza con la quale viene assegnato un determinato valore. Per il calcolo della funzione costo di ciascun pixel, è stato usato un algoritmo di tipo \textit{semi-global matching}, presente nelle librerie open source di visione computazionale \textit{OpenCV} \cite{opencv}. Questo algoritmo, scritto nel linguaggio \textit{C++}, di per se produrrebbe in output solo la mappa di disparità. L'algoritmo è stato quindi opportunamente modificato per poter estrarre la funzione costo di ciascun punto. Si ha quindi in output anche una matrice, delle stesse dimensioni dell'immagine originale, ma che ha per ciascuna cella la funzione costo. Successivamente la matrice viene convertita in formato \textit{.mat}, per rendere il tutto più facile da utilizzare con il linguaggio di programmazione \textit{MATLAB}. Poi, con script \textit{MATLAB}, vengono calcolate le confidenze con diverse metriche. Le immagini utilizzate sono state prese dal dataset \textit{Midleburry} \cite{dataset_2006_1,dataset_2006_2} disponibili su \url{http://vision.middlebury.edu/stereo/data/}. \newline
		Prima di proseguire però, si rende necessario dare alcune definizioni:  		
		
		\begin{itemize}
			\item $c(d)$: il valore del costo assegnato ad una ipotetica mappa di disparità $d$, per un pixel di coordinate $(x,y)$, è denotato con $c(x,y,d)$ o $c(d)$, se le coordinate del pixel non sono ambigue;
			
			\item $c_{1}$: il minimo valore del costo di un pixel è definito con $c_{1}$ e il corrispondente valore di disparità da $d_{1}$; $c_{1}=c(d_{1})=\min\{c(d)\}$;
			
			\item $c_{2}$: con $c_{2}$ viene denotato il secondo valore più piccolo in $d_{2}$, mentre con $c_{2m}$ si denota il secondo minimo locale più piccolo. Nel calcolo del secondo minino, bisogna anche tener conto di quei casi dove vi sono due minimi molto vicini e con valori molto simili; in questo caso si escludono minimi che non sono ad una certa distanza dal minimo principale.
			\label{item:definizioni}
		\end{itemize}
			
		\noindent Seguono quindi tutte le varie tecniche utilizzate, raggruppate secondo l'aspetto del costo che considerano \cite{indoors_outdoors}.
		
		
		
		\section{Proprietà locali della curva}
		\label{sec:localProperties}	
			In questo genere di metriche, si sfrutta il fatto che la forma della curva di costo intorno al minimo (la nitidezza o la planarità) è indice di certezza nel confronto.
			
			\paragraph{Curvature (CUR)}
			\label{par:curvature}
			
				E' largamente utilizzata nella letteratura \cite{indoors_outdoors}, ed è definita come
				
				\begin{equation}
					C_{CUR}=\frac{-2c(d_{1})+c(d_{1}-1)+c(d_{1}+1)}{2}
					\label{eq:CUR}
				\end{equation} 
			
				\noindent se $d_{1}-1$ o $d_{1}+1$ sono fuori dal range di disparità, il punto minimo $c(d_{1})$ viene usato due volte. Il tutto viene diviso per 2 per garantire valori compresi tra zero e uno.
			
			
			\paragraph{Local Curve (LC)} 
			\label{par:local}
			
				Molto simile alla misura \textit{CUR}, la \textit{Local Curve} è descritta da
				
				\begin{equation}
					C_{LC}=\frac {\max\bigr\{ c(d_{1}-1) ,c(d_{1}+1) \bigr\} - c_{1}} {\gamma}
					\label{eq:LC}
				\end{equation}
				
				\noindent il parametro $\gamma$ verrà poi scelto tale da garantire una distribuzione del costo più uniforme possibile tra zero e uno.
			
			
			
		\section{Minimo locale della curva}
		\label{sec:localMinima}	
		
			Si basa sul concetto che la presenza di altri candidati è un'indicazione di incertezza, mentre la loro assenza di certezza.
			
			\paragraph{Peak Ratio Naive (PKRN)} 
			\label{par:PKRN}
		
				A differenza del \textit{Peak Ratio (PKR)}, che calcola il costo con la formula \ref{eq:PKR}
		
				\begin{equation}
					C_{PKR}=\frac{c_{2m}}{c_{1}}
					\label{eq:PKR}
				\end{equation}
			
				\noindent il \textit{PKRN} non richiede che il numeratore sia un minimo locale. Inoltre la formula è leggermente diversa da quella proposta in letteratura \cite{mercedes}
			
				\begin{equation}
					C_{PKRN}=\frac{c_{2} + \epsilon}{c_{1} + \epsilon} - 1
					\label{eq:PKRN}
				\end{equation}
		
				\noindent \textit{PKRN} può essere visto come una combinazione del \textit{PKR} e \textit{CUR}, che assegna bassa confidenza per le corrispondenze con minimi piatti o concorrenti forti. Anche se le modifiche al \textit{PKRN} violano leggermente la metrica originale, ha i seguenti vantaggi rispetto alla controparte originale:
				
				\begin{itemize}
					\item le rare singolarità in cui il denominatore sia nullo non sono più presenti;
					\item piccole variazioni nei costi dovuti al rumore ai livelli bassi del costo, non hanno un forte impatto nella metrica; 
					\item potendo scegliere il valore di $\epsilon$, il range dei possibili valori può essere adattato, al fine di omogeneizzare la misura tra zero e uno.
					\label{item:PKRN}			
				\end{itemize}
				
			\paragraph{Maximum Margin (MMN)}
			\label{par:MMN}
			
				il margine tra $c_{1}$ e $c_{2}$ è anch'esso indicazione di confidenza. \textit{MMN} è definito dalla formula
				
				\begin{equation}
					C_{MMN}=c_{2}-c_{1}
					\label{eq:MMN} 
				\end{equation} 	
				
			
			\paragraph{Nonlinear Margin (NLM)}
			\label{par:NLM}
			
				è definito come
				
				\begin{equation}
					C_{NLM}= e^{\frac{ c_{2}-c_{1}} {2\sigma_{NLM}^2}}-1
					\label{eq:NLM}
				\end{equation}
				
				\noindent le variazioni del parametro $\sigma_{NLM}$ verranno poi discusse nella sezione \ref{sec:parametri}.	
				
				
		\section{Intera curva}
		\label{sec:entireCost}
		
			Questi metodi convertono la funzione costo in una distribuzione di probabilità sulla disparità.
			
			\paragraph{Maximum Likelihood Metric (MLM)}
			\label{par:MLM}
			
				Insieme a \textit{PKRN} è una delle metriche più promettenti. Entrambe hanno ottenuto risultati sopra la media sia su immagini indoor che outdoor \cite{indoors_outdoors}.
				La \textit{Maximum Likelihood Metric} è definita come
				
				\begin{equation}
					C_{MLM}= \frac{e^{-\frac{c_{1}}{2\sigma_{MLM}^2}}}{\sum_{d} e^{-\frac{c(d)}{2\sigma_{MLM}^2}}}
					\label{eq:MLM}
				\end{equation}  	
			
				\noindent In questo caso $\sigma_{MLM}$ rappresenta l'incertezza della disparità, e anche per questo caso la sua variazione verrà discussa nella sezione \ref{sec:parametri}.
		
		
			\paragraph{Attainable Maximun Likelihood (AML)}
			\label{par:AML}
						
				è una variante di \textit{MLM} che modella il costo per un particolare pixel usando una distribuzione Gaussiana centrata nel minimo valore di costo che è stato finora calcolato per quel pixel ($c_{1}$ nella nostra notazione).
				
				\begin{equation}
					C_{AML}=\frac{e^{-\frac{(c_{1}-c_{1})^2}{2\sigma_{AML}^2}}}{\sum_{d} e^{-\frac{(c(d)-c_{1})^2}{2\sigma_{AML}^2}}}=\frac{1}{\sum_{d} e^{-\frac{(c(d)-c_{1})^2}{2\sigma_{AML}^2}}}
					\label{eq:AML}
				\end{equation} 
				
				
			\paragraph{Winner Margin Naive (WMNN)}
			
				esiste il \textit{Winner Margin}, che richiede che al numeratore vi sia un minimo locale, ma come per il \textit{PKRN} definiamo la versione naive come
				
				\begin{equation}
					C_{WMNN}=\frac{c_{2}-c_{1}}{\sum_{d}c(d)}
					\label{eq:WMNN} 
				\end{equation}
					
				
				
		\section{Consistenza fra disparità di destra e sinistra}
		\label{sec:leftRight}
			
			Questa tipologia di misure consiste nel fatto che, idealmente, un punto nella mappa di disparità destra dovrebbe essere lo stesso nella mappa di disparità sinistra. Fin ora abbiamo denotato il valore del costo con $c(x,y,d)$ avendo come riferimento l'immagine di sinistra, ma per chiarezza chiameremo $c_{R}(x_{R},y,d_{R})$ il valore del costo ottenuto tenendo come riferimento l'immagine di destra. Inoltre se $d$ è il valore di disparità dell'immagine di sinistra, $d_{R}$ è quello dell'immagine di destra. Questo genere di misure risulterà più complicata delle precedenti, in quanto prima di calcolare la funzione costo, si rende necessario calcolare prima la disparità sia per l'immagine di destra che quella di sinistra. 		
		
			\paragraph{Left Right Consistency (LRC)}
			\label{par:LRC}
			
				\textit{Left Right Consistency (LRC)} viene calcolato prendendo il valore disparità calcolato in una immagine, e proiettandolo nell'altra immagine. Se la differenza nei valori è inferiore a una determinata soglia, allora il pixel è occluso. Questo procedimento viene poi ripetuto anche al contrario, cioè proiettando la seconda immagine nella prima. Inoltre il costo di \textit{LRC} viene calcolato come segue:
				
				\begin{equation}
					C_{LRC}(x,y)=\abs[\big]{d_{1}-D_{R}(x-d_{1},y)}
					\label{eq:LRC}
				\end{equation}	
				
				\noindent con $d_{1}=\argmin_{d}\bigr\{c(x,y,d)\bigr\}$ e $D_{R}(x-d_{1},y)=\argmin_{d_{R}}\bigr\{c_{R}(x-d_{1},y,d_{R})\bigr\}$.
				
			\paragraph{Left Right Difference (LRD)}	
			\label{par:LRD}
			
				\textit{Left Right Difference (LRD)} è una misura proposta per la prima volta in \cite{mordohai_pami}. Essa considera sia i due minimi della disparità di sinistra, ma anche il minimo di quella di destra. E' definita come
				
				\begin{equation}
					C_{LRD}(x,y)=\frac{c_{2}-c_{1}}{\abs[\big]{c_{1}-\min\{c_{R}(x-d_{1},y,d_{R})\}}}
					\label{eq:LRD}
				\end{equation}
				
				\noindent L'idea è che finestre di pixel corrispondenti dovrebbero risultare in valore di costo molto simili, e quindi piccoli valori al denominatore. Questa misura dovrebbe salvaguardare da due possibili errori:
				
				\begin{itemize}
					\item se il margine $c_{2}-c_{1}$ è grande, ma il pixel ha una corrispondenza errata, il denominatore sarà grande, e la confidenza bassa;
					
					\item se il margine è piccolo, la misura è possibile che sia ambigua, in questo caso se il denominatore è piccolo denota che è stata creata con successo una corrispondenza fra due pixel
					
				\label{item:LRD}	
				\end{itemize}			
				
				\nullpage
%%--------------------------- RISULTATI ----------------------------------------------%%

	\chapter{Risultati}
	\label{sec:risultati}
	\pagestyle{fancy}				
	
		Tutte le misure effettuate vengono confrontate con una mappa di disparità \textit{ground truth} che contiene i veri valori di disparità per ogni pixel. Questa mappa è sempre disponibile nei dataset utilizzati \cite{dataset_2006_1, dataset_2006_2}, per tutte le immagini e per tutte le risoluzioni. La disparità \textit{ground truth} viene calcolata utilizzando sempre una coppia di videocamere, ma aggiungendo anche uno o più proiettori che illuminano la scena con dei pattern specifici. Ogni telecamera utilizza quindi i pattern per determinare un codice univoco per ciascun pixel. Trovare quindi le corrispondenze si traduce banalmente nel verificare quali pixel delle due immagini hanno lo stesso codice \cite{ground_truth}.  			
		
		\begin{SCfigure}[\sidecaptionrelwidth][h!]
			\includegraphics[width=0.5\textwidth]{./figures/ground_truth.png}
			\caption{Configurazione del proiettore e della coppia di videocamere per il calcolo della disparità ground truth; si può notare come il proiettore illumina la scena con dei pattern diversi per facilitare il compito delle videocamere.}
			\label{fig:groundtruth}
		\end{SCfigure}
		
		\noindent Prima di continuare definiamo l'errore di disparità come
		
		\begin{equation}
			e_{d}=\abs{d_{GT}-d}
			\label{eq:errore}
		\end{equation} 
		
		\noindent Dove $d_{GT}$ è la disparità \textit{ground truth} e $d$ sono i valori di disparità ottenuti con l'algoritmo \textit{SGM}. \newline Per valutare la capacità delle misure di confidenza di predire dove una disparità è corretta, è stato creato uno script \textit{MATLAB} che ordina prima l'errore di disparità in ordine crescente, e poi ordina l'errore per ogni misura in ordine decrescente rispetto la sua confidenza. Successivamente si calcola l'errore globale selezionando prima il $5\%$, in due modi: 
		
		\begin{enumerate}
			\item nel primo metodo si misura la percentuale di pixel che ha un errore di disparità maggiore di uno, questo si fa perché ovviamente se l'errore è minore di uno, non vi è alcun pixel di differenza fra le due;
			
			\item nel secondo si misura semplicemente l'errore medio.
			\label{enum:errore}
		\end{enumerate}
				
		\noindent Si ripete poi con il $10\%$ e così via sino al $100\%$. Prima di confrontare le varie metriche si è pero' trovato il parametro ottimale per quelle con parametri variabili.
		
		\section{Variazione parametri}
		\label{sec:parametri}
		
			In questa sezione, prima di confrontare le misure, verificheremo quali parametri sono più adatti per quelle che dipendono da tali. Consideriamo quindi la \textit{Local Curve}, \textit{Peak Ratio Naive}, \textit{Nonlinear Margin}, \textit{Maximum Likelihood metric} e \textit{Attainable Maximun Likelihood}.
		
			\paragraph{Variazione parametro $\bm{\gamma}$ per \textit{LC}}
			\label{par:gamma}
			
				Ora indagheremo quali effetti produce la variazione del parametro $\gamma$. Come prima cosa si è osservato per quale valore si ha una distribuzione più uniforme tra $0$ e $1$. Come si può vedere dalla figura \ref{fig:gammaLC}, si ha una
		
				\begin{figure}[H]
					\centering
					\includegraphics[width=0.6\textwidth]{./figures/gamma_LC.png}
					\caption{Distribuzioni diverse con valori di $\gamma$ diversi.}
					\label{fig:gammaLC}
				\end{figure} 
				
			 	\noindent migliore distribuzione per $\gamma=1$. Per quanto riguarda l'errore medio invece, non si ottiene nessun cambiamento significativo sia con valori di $\gamma$ molto alti, sia con valori molto bassi. Come valore finale si è quindi deciso per un $\gamma$ pari a $1$; facendo ciò non sarà anche necessario riscalare la funzione costo, in quanto è già compresa tra zero e uno.
		
		
			\paragraph{Variazione parametro $\bm{\epsilon}$ per \textit{PKRN}}
			\label{par:epsilon}
		
				Come prima, verifichiamo come si comporta la distribuzione della funzione al cambiare del parametro $\epsilon$. Si nota che per valori intorno a uno, la distribuzione non supera il massimo di uno, con valori minori di uno invece lo si supera. Per quanto riguarda gli errori rispetto la \textit{ground truth}, si notano dei lievi miglioramenti per valori di $\epsilon$ molto piccoli, intorno a un decimo; lo si può notare in figura \ref{fig:epsilonPKRN}. Si è notato inoltre che dopo il valore di $0,128$ non si hanno cambiamenti. Si sceglie quindi $\epsilon=0.128$. Notare che in questo modo è necessario riscalare il valore della metrica, in quanto il suo massimo è abbondantemente sopra l'uno; per farlo è sufficiente dividere ogni singolo costo per il costo massimo.
			
				\begin{figure}[H]
					\centering
					\includegraphics[width=0.6\textwidth]{./figures/epsilon_PKRN.png}
					\caption{Dettaglio della curva dell'errore della metrica \textit{PKRN}, notare che con $\epsilon$ più piccolo si hanno dei lievi ma visibili miglioramenti; in giallo il valore di \textit{ground truth}}
					\label{fig:epsilonPKRN}
				\end{figure} 
			
	
			\paragraph{Variazione parametro $\bm{\sigma}$ per \textit{NLM}}
			\label{par:sigmaNLM}
			
				Ripetiamo ancora una volta il procedimento, i risultati sono pressoché simili al \textit{LC}, cioè grosse variazioni di distribuzione e trascurabili variazioni di errore per differenti valori di $\sigma$. Dopo qualche tentativo con diversi parametri, si arriva alla conclusione che i risultati migliori si ottengono con $\sigma=0,85$. Si fa notare però, che con valori di $\sigma$ molto piccoli, l'errore può peggiorare di molto, mentre con valori molto grandi l'errore rimane pressoché inalterato.
							
				\begin{figure}
					\centering
					\includegraphics[width=0.55\textwidth]{./figures/sigma_NLM.png}
					\caption{Diversi valori di distribuzione per diversi valori di $\sigma$.}
					\label{fig:sigmaNLM}
				\end{figure} 
			
			
			\paragraph{Variazione parametro $\bm{\sigma}$ per \textit{MLM}}	 	 	
			\label{par:sigmaMLM}
		 	 
		 	 	A differenze delle altre misure, per essere utilizzata al meglio la si deve per forza riscalare. Infatti i valori che permetterebbero un costo compreso tra zero e uno, sarebbero completamente sballati per quanto riguarda gli errori. Per garantire quinti una certa uniformità e un errore non esagerato, si è quindi scelto un valore di $\sigma$ pari a $0,3$. 
		 	 	
		 	 	\begin{figure}[H]
			 	 	\centering
			 	 	\includegraphics[width=0.55\textwidth]{./figures/sigma_MLM.png}
			 	 	\caption{Diversi valori di distribuzione per diversi valori di $\sigma$.}
			 	 	\label{fig:sigmaMLM}
		 	 	\end{figure}
		 	 	
		 	 \paragraph{Variazione parametro $\bm{\sigma}$ per \textit{AML}}	 	 	
		 	 \label{par:sigmaAML}	
		 	 	
		 	 	Il suo comportamento è molto simile a \textit{MLM}, i migiori risultati si ottengono con $\sigma$ del valore di $0,4$.
		 	 	
		 	 	
		 	 	
		\section{Confronto delle misure}
		\label{sec:confronto}		 	
			  
		
			\begin{figure}[H]
				\subfloat[][\emph{Misura Curvature.}]
				{\includegraphics[width=.228\textwidth]{./figures/CUR.png}} \quad
				\subfloat[][\emph{Misura Local Curve.}]
				{\includegraphics[width=.228\textwidth]{./figures/LC.png}} \quad 
				\subfloat[][\emph{Misura Peak Ratio Naive.}]
				{\includegraphics[width=.228\textwidth]{./figures/PKRN.png}} \quad
				\subfloat[][\emph{Misura Maximum Margin.}]
				{\includegraphics[width=.228\textwidth]{./figures/MMN.png}} \quad
				\subfloat[][\emph{Misura Nonlinear Margin.}]
				{\includegraphics[width=.228\textwidth]{./figures/NLM.png}} \quad
				\subfloat[][\emph{Misura Maximum Likelihood metric.}]
				{\includegraphics[width=.228\textwidth]{./figures/MLM.png}} \quad 
				\subfloat[][\emph{Misura Attainable Maximum Likelihood.}]
				{\includegraphics[width=.228\textwidth]{./figures/AML.png}} \quad
				\subfloat[][\emph{Misura Winner Margin Naive.}]
				{\includegraphics[width=.228\textwidth]{./figures/WMNN.png}}
				
				\caption{Diverse misure di confidenza.}
				\label{fig:disparità&costi}
			\end{figure}
			
			Cominciamo dal dire cosa aspettarci dai due confronti descritti prima. Per il primo grafico ci aspettiamo di trovare una curva che resta a zero per una determinata percentuale di confidenze, e che  poi tende a crescere in maniera pressoché lineare per le successive. 
			
			\begin{wrapfloat}{figure}{I}{0pt}
				\includegraphics[width=0.48\textwidth]{./figures/result3.png}
				\caption{Errore di disparità medio nella figura \textit{Aloe}.}
				\label{fig:risultati2}
			\end{wrapfloat}
			
			\noindent Per il secondo confronto ci aspetteremo che l'errore di riferimento sia monotono crescente, mentre le misure possono assumere andamenti più casuali, al patto che abbiano errore sempre maggiore di quello di riferimento. Ovviamente la misura migliore sarà quella con la curva il più possibile vicino all'errore di \textit{ground truth}. Passando quindi al confronto, si nota che le diverse metriche si comportano in maniera differente a seconda dell'immagine. Nel complesso però, le due che sembrano avere risultati migliori sono la \textit{MLM} e \textit{AML}. Questo è chiaramente visibile nei grafici riportati in figura \ref{fig:risultati}.Questo è il risultato dove differenzia di più tutte le misure; questo vuol dire che in certe immagini le misure si equivalgono molto, mentre in altre sono molto diverse. Non succede mai però che \textit{MLM} e \textit{AML} siano nettamente peggiori, succede invece che a volte una delle due sia meglio di un altra e viceversa. Altro caso, è quando i grafici si incrociano, questo vuol dire che per una certa percentuale di confidenze è meglio una, mentre poi è meglio un'altra. Questo succede ad esempio nella figura \ref{fig:risultati2}, dove la metrica \textit{NonLinear Margin} è la migliore di tutte per quasi il 40\% dei pixel considerati, venendo poi superata, ancora una volta, da \textit{MLM} e \textit{PKRN}. Come previsto, anche la metrica \textit{PKRN} ottiene buoni risultati, superando tutte soprattutto nella prima percentuale di pixel considerati. 		
			
			\begin{figure}[H]
				\centering
				\subfloat[][\emph{Numero di pixel con errore di disparità maggiore di uno.}]
				{\includegraphics[width=0.48\textwidth]{./figures/result1.png}} \quad
				\subfloat[][\emph{Errore di disparità medio.}]
				{\includegraphics[width=0.485\textwidth]{./figures/result2.png}} \quad
				\subfloat[][\emph{Numero di pixel con errore di disparità maggiore di uno.}]
				{\includegraphics[width=0.48\textwidth]{./figures/result4.png}} \quad
				\subfloat[][\emph{Errore di disparità medio.}]
				{\includegraphics[width=0.484\textwidth]{./figures/result5.png}}
							
				\caption{Grafici dei risultati utilizzando l'immagine \textit{Bowling2} dal dataset \textit{Middlebury}}
				\label{fig:risultati}
			\end{figure}	
			
			\noindent Per quanto riguarda le misure del tipo consistenza fra disparità di destra e sinistra, la migliore delle due sembra essere \textit{LRD}. Come verificato in \cite{mordohai_pami}, questa misura è migliore di \textit{LRC} in praticamente tutte le immagini considerate e per quasi tutte le percentuali di pixel. Entrambe comunque si comportano molto bene anche rispetto le misure descritte nel capitolo \ref{sec:confidenza}; infatti la curva che indica il numero di pixel con errore di disparità maggiore di uno, rimane piatta fino a circa il $50\%$ dei pixel considerati (il \textit{ground truth} arriva al $65\%$) mentre anche nel migliore dei casi, le altre misure non riescono a superare il $30\%$.  
			
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.48\textwidth]{./figures/result7.png}
				\caption{Misura \textit{LRD} contro \textit{LRC}.}
				\label{fig:LRDvsLRC}
			\end{figure}
			

			 
			 \nullpage
			
%%--------------------------- COMBINAZIONE DI MISURE ------------------------------------%%						
	
	\chapter{Combinazione di misure}
	\label{sec:combinazione}
	\pagestyle{fancy}
				
		Per combinazione di misure, si intende il combinarne più insieme al fine di migliorarne i risultati. Considerando le misure di confidenza come probabilità, la cosa più semplice da fare sarebbe quella di dire che, essendo indipendenti, la loro combinazione non è altro che il loro prodotto. In realtà però, non è del tutto corretto definirle indipendenti, in quanto tutte dipendono dalla stessa ‘‘matrice dei costi’’, calcolata con il medesimo algoritmo (in questo caso \textit{SGM}). In questa tesi però non ne terremo conto, calcolando la combinazione di misure solo come semplice moltiplicazione di alcune di esse. Come combinazione sono state usate:
		
		\begin{itemize}
			\item combinazione di \textit{AML} e \textit{MLM} $C_{comb1}=C_{AML}\cdot C_{MLM}$;
			
			\item combinazione delle tre migliori $C_{comb2}=C_{AML}\cdot C_{MLM}\cdot C_{PKRN}$;
			
			\item combinazione fra \textit{NLM} e \textit{MLM}, infatti la metrica \textit{NLM} è risultata competitiva in certi dataset per circa il primo $40\%$ dei pixel, per poi essere superata da \textit{MLM} $C_{comb3}=C_{NLM}\cdot C_{MLM}$. 
			\label{item:combinazioni}		
		\end{itemize}
		
		\noindent Ovviamente prima di moltiplicarle, bisogna verificare che la loro distribuzione sia compresa tra zero e uno.
		
		
		\section{Risultati}
		\label{sec:risultatiCombinazioni}

			\begin{SCfigure}[\sidecaptionrelwidth][h!]
				\centering
				\includegraphics[width=0.48\textwidth]{./figures/result6.png}
				\caption{Dettaglio dell'errore medio per la combinazione di diverse misure, in questo caso la migliore resta comunque \textit{AML}, per poi essere raggiunta dalla sua combinazione con \textit{MLM}.}
				\label{fig:combinazioni}
			\end{SCfigure} 

		
			La migliore combinazione risulta essere la prima, poi la seconda e infine la terza. La prima combinazione riesce sempre ad essere migliore di \textit{MLM}, mentre solo a volte migliore di \textit{AML}. La seconda migliora, e non di poco, la metrica \textit{PKRN}, mentre la terza è peggiore delle singole misure per i primi $50 \%$ di pixel, ma in quelli successivi risulta vincente. Nel complesso quindi, questo genere di combinazioni, può riuscire a migliorare i risultati di qualcosa, ma un uso sbagliato può riuscire a peggiorarli di molto. \newline
			Per riuscire a migliore questi risultati, si potrebbe pensare a combinazioni più complicate, come utilizzare un approccio di tipo \textit{machine learning}, utilizzando \textit{random tree ensembles} descritto in \cite{combinazioni_complicate}.
	

%%---------------------------- APPENDICI ----------------------------------------%%		
	\appendix 
	\addcontentsline{toc}{chapter}{Appendici}
	\renewcommand\chaptername{Appendice}
	
	\chapter{Codice MATLAB utilizzato}
	\label{sec:codice}
	
		In questa appendice viene riportato solo il codice \textit{MATLAB} che calcola le mappe di confidenza con le varie tecniche descritte nel paragrafo \ref{sec:confidenza} e nel paragrafo \ref{sec:combinazione}; si riporta inoltre il codice utilizzato per analizzare i risultati ottenuti.
	
		\section{compute\_confidence.m}
		\label{sec:computeConfidence}
		
			Questo script computa la mappa di disparità per \textit{CUR}, \textit{LC}, \textit{PKRN}, \textit{MMN}, \textit{NLM}, \textit{MLM}, \textit{AML} e \textit{WMNN}. Calcola inoltre la combinazione delle confidenze.
	
			\lstinputlisting[basicstyle=\scriptsize]{./code/compute_confidence.m}
		
		\section{left\_right\_confidence.m}
		\label{sec:leftright}
			\lstinputlisting[basicstyle=\scriptsize]{./code/left_right_confidence.m}
		
		\section{result.m}
		\label{sec:result}
			\lstinputlisting[basicstyle=\scriptsize]{./code/result.m}	
			
		%\newpage
		%\section{funcSADL2R.m}
		%\label{sec:funcSADL2R}
		%	\lstinputlisting[basicstyle=\scriptsize]{./code/funcSADL2R.m}
			
		%\newpage
		%\section{funcSADR2L.m}
		%\label{sec:funcSADR2L}
		%	\lstinputlisting[basicstyle=\scriptsize]{./code/funcSADR2L.m}		




%%---------------------------- BIBLIOGRAFIA ----------------------------------------%%
	\nullpage
	
	\begin{thebibliography}{1}
	\label{bibliografia}
	\addcontentsline{toc}{chapter}{Bibliografia}
		
		\bibitem{fusiello}
		A. Fusiello,
		\emph{Visione Computazionale, appunti delle lezioni},
		\url{http://profs.sci.univr.it/~fusiello},
		2008.

		\bibitem{mercedes}
		D. Pfeiffer, S. Gehrig, N. Schneider,
		\emph{Exploiting the Power of Stereo Confidences},
		IEEE Conference on Computer Vision and Pattern Recognition, 2013.
	
		\bibitem{correlation}
		D. Scharstein, R. Szeliski, 
		\emph{A taxonomy and evaluation of
		dense two-frame stereo correspondence algorithms}, 
		IJCV,47(1-3):7–42, 2002.
		
		\bibitem{SGM}
		H. Hirschmüller, 
		\emph{Accurate and efficient stereo processing
		by semi-global matching and mutual information}, 
		IEEE CVPR, pages 807–814, San Diego, USA, June 2005.
		
		\bibitem{mordohai_pami}
		X. Hu, P. Mordohai,
		\emph{A Quantitative Evaluation of Confidence Measures for Stereo Vision},
		IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012.
		
		\bibitem{indoors_outdoors}
		X. Hu, P. Mordohai,
		\emph{Evaluation of Stereo Confidence Indoors and Outdoors},
		IEEE Conference on Computer Vision and Pattern Recognition (CVPR), San Francisco, USA, June 2010.
		
		\bibitem{dataset_2006_1}
		D. Scharstein, C. Pal,
		\emph{Learning conditional random fields for stereo},
		IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2007), Minneapolis, MN, June 2007.
		
		\bibitem{dataset_2006_2}
		H. Hirschmüller, D. Scharstein,
		\emph{Evaluation of cost functions for stereo matching},
		IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2007), Minneapolis, MN, June 2007.
		
		\bibitem{opencv}
		G. Bradski,
		\emph{The OpenCV Library},
		\url{http://opencv.org/},
		Dr. Dobb's Journal of Software Tools,  2000.
		
		\bibitem{ground_truth}
		D. Scharstein, R. Szeliski,
		\emph{High-Accuracy Stereo Depth Maps Using Structured Light},
		Proc. CVPR, volume I, pages 195–202, 2003.
		
		\bibitem{combinazioni_complicate}
		R. Haeusler, R. Nair, D. Kondermann,
		\emph{Ensemble Learning for Confidence Measures in Stereo Vision}.
		
		


		
	\end{thebibliography}


\end{document}